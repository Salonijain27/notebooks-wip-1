{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMapD and PyGDF Demo on NY Taxi Data Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use PyMapD to create and populate a table of NY Taxi data from a CSV file.  Then, we query the MapD database to get a PyGDF GPU dataframe and manipulate the data using groupby, join and other dataframe operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress CSV archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -kf ./data/nytaxi/nytaxi_pre_mapd_200k.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MapD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vendor_id', 'rate_code', 'store_and_fwd_flag', 'passenger_count', 'trip_time_in_secs', 'trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'tolls_amount', 'tip_amount', 'total_amount', 'mta_tax', 'fare_amount', 'payment_type', 'surcharge', 'pickup_datetime_year', 'pickup_datetime_month', 'pickup_datetime_day', 'pickup_datetime_hours', 'dropoff_datetime_year', 'dropoff_datetime_month', 'dropoff_datetime_day', 'dropoff_datetime_hours']\n",
      "['str', 'int', 'str', 'int', 'int', 'float64', 'float64', 'float64', 'date', 'date', 'float64', 'float64', 'float64', 'float64', 'float64', 'str', 'float64', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int']\n",
      "[<nvstrings count=200000>, <cudf.Series nrows=200000 >, <nvstrings count=200000>, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <nvstrings count=200000>, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >, <cudf.Series nrows=200000 >]\n"
     ]
    }
   ],
   "source": [
    "df = cudf.read_csv(\"data/nytaxi/nytaxi_pre_mapd_200k.csv\")\n",
    "#print(df.dtypes)\n",
    "dnames = list(df)\n",
    "types = []\n",
    "for i in range (len(list(df))):\n",
    "    tdtype = str(df.dtypes[i])\n",
    "    if(tdtype == 'int32'):\n",
    "        tdtype = 'str'\n",
    "    elif(tdtype == 'int64'):\n",
    "        tdtype = 'int'\n",
    "    elif(tdtype == 'datetime64[ms]'):\n",
    "        tdtype = 'date'\n",
    "    types.append(tdtype)\n",
    "\n",
    "print(dnames)\n",
    "print(types)\n",
    "df2 = cudf.io.csv.read_csv_strings('data/nytaxi/nytaxi_pre_mapd_200k.csv', delimiter=',',\n",
    "                                       names = dnames,\n",
    "                                       dtype= types,\n",
    "                                       quoting=True,\n",
    "                                       doublequote=False,\n",
    "                                       skiprows=1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-88c144c4f05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "print(df2.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5cc0934cc03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"payment_type\"], df[\"vendor_id\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('foo3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nrows', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby lat lon grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to group each record by their pickup location. We will to round the lat lon with the ``round_latlon`` method.  By using ``.applymap``, the rounding method will be compiled into GPU code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def round_latlon(x):\n",
    "    scale = 5\n",
    "    return floor(x * scale) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_df = df.loc[:, ['pickup_longitude', 'pickup_latitude', 'tip_amount', 'fare_amount']] \n",
    "print(df['tip_amount'])\n",
    "group_df['pickup_longitude'] = group_df['pickup_longitude'].applymap(round_latlon)\n",
    "group_df['pickup_latitude'] = group_df['pickup_latitude'].applymap(round_latlon)\n",
    "\n",
    "group_df['tip_ratio'] = group_df['tip_amount'] / group_df['fare_amount']\n",
    "print(group_df['tip_ratio'], group_df['tip_amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('group df rows', len(group_df))\n",
    "print(group_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we run groupby and specify the aggregating methods on each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda,jit,float32\n",
    "\n",
    "# Aggregating methods to apply to each column\n",
    "\n",
    "aggs = {\n",
    "    'tip_amount': ['mean'],\n",
    "    'fare_amount': ['mean', 'count'], ##std is not currently impletmented in RAPIDS 0.5.1.  Therefore, we need a work around (thanks Jiwei Liu!)\n",
    "    'tip_ratio': ['mean']\n",
    "}\n",
    "\n",
    "grouped_stats = group_df.groupby(['pickup_longitude', 'pickup_latitude']).agg(aggs)\n",
    "grouped_std = [group_df['fare_amount'].std()]*len(grouped_stats) ### STD is a SPSA method, while the other aggs are SPMA.  This requires us to calculate it seperatedly, put the values in an series  of ismilar size, and then join it to the dataframe\n",
    "grouped_stats['std_fare_amount'] = grouped_std\n",
    "print('total groups', len(grouped_stats))\n",
    "print(grouped_stats.head())\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the grouped dataframe by `count_fare_amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_stats.sort_values('count_fare_amount', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby payment type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group by categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_pay = df.loc[:, ['payment_type', 'tip_amount', 'fare_amount']]\n",
    "print(group_pay)\n",
    "group_pay['tip_ratio'] = group_df['tip_ratio']\n",
    "print(group_df['tip_ratio'])\n",
    "groupby_payment = group_pay.groupby(['payment_type']).mean()\n",
    "display(groupby_payment.sort_values('mean_tip_ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress CSV archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -kf ./data/nytaxi/nytaxi_pre_mapd_200k.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest data from MapD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = con.select_ipc_gpu(\"\"\"\n",
    "SELECT  \n",
    "payment_type, pickup_longitude, pickup_latitude, tip_amount, total_amount, fare_amount\n",
    "FROM nytaxi_subset \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of the result from `con.select_ipc_gpu` is a GPU dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nrows', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def round_latlon(x):\n",
    "    scale = 5\n",
    "    return floor(x * scale) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_df = df.loc[:, ['pickup_longitude', 'pickup_latitude', 'tip_amount', 'fare_amount']] \n",
    "\n",
    "group_df['pickup_longitude'] = group_df['pickup_longitude'].applymap(round_latlon)\n",
    "group_df['pickup_latitude'] = group_df['pickup_latitude'].applymap(round_latlon)\n",
    "\n",
    "group_df['tip_ratio'] = group_df['tip_amount'] / group_df['fare_amount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we run groupby and specify the aggregating methods on each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Aggregating methods to apply to each column\n",
    "grouped_std = group_df['fare_amount'].std()\n",
    "aggs = {\n",
    "    'tip_amount': ['mean'],\n",
    "    'fare_amount': ['mean', 'count'], ##std is not currently impletmented in RAPIDS 0.5.1.  Therefore, we need a work around (thanks Jiwei Liu!)\n",
    "    'tip_ratio': ['mean']\n",
    "}\n",
    "print(aggs)\n",
    "print(len(aggs))\n",
    "\n",
    "#print(group_df.groupby(['pickup_longitude', 'pickup_latitude']).agg(aggs))\n",
    "grouped_stats = group_df.groupby(['pickup_longitude', 'pickup_latitude']).agg(aggs)\n",
    "#grouped_stats = group_stats.assign(std_fare_amount=grouped_std)\n",
    "for i in range(len(grouped_stats)):\n",
    "    grouped_stats[i].std_fare_amount= grouped_std\n",
    "\n",
    "print('total groups', len(grouped_stats))\n",
    "grouped_stats.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the grouped dataframe by `fare_amount_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats.sort_values('fare_amount_count', ascending=False).head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby payment type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group by categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_pay = df.loc[:, ['payment_type', 'tip_amount', 'fare_amount']]\n",
    "group_pay['tip_ratio'] = group_df['tip_ratio']\n",
    "\n",
    "groupby_payment = group_pay.groupby(['payment_type']).mean()\n",
    "groupby_payment.sort_values('tip_ratio', ascending=False).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join table with payment_type meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.join()` to add a description column for each payment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "payment_code = {\n",
    "    'CRD': 'Credit Card',\n",
    "    'CSH': 'Cash',\n",
    "    'NOC': 'No Charge',\n",
    "    'DIS': 'Dispute',\n",
    "    'UNK': 'Unknown',\n",
    "}\n",
    "\n",
    "payment_meaning = pygdf.DataFrame()\n",
    "\n",
    "# Customize codes.dtype to match storage type from mapd\n",
    "src_cat = group_pay.payment_type\n",
    "cat = pandas.Categorical(payment_code.keys(), categories=src_cat.cat.categories)\n",
    "payment_meaning['payment_type'] = pygdf.Series.from_categorical(cat, codes=cat.codes.astype(src_cat.data.dtype))\n",
    "\n",
    "payment_meaning['payment_meaning'] = pandas.Categorical(payment_code.values())\n",
    "payment_meaning = payment_meaning.set_index('payment_type')\n",
    "\n",
    "payment_meaning.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = groupby_payment.set_index('payment_type').join(payment_meaning)\n",
    "joined.sort_values('tip_ratio', ascending=False).to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
